import gradio as gr
import requests
import os
import shutil
import uuid
import time
import threading
from pathlib import Path
from datetime import datetime
from queue import Queue
import subprocess
import platform
import ffmpeg
import sys
import codecs
import psutil
import time
from threading import Event
import psutil
from pynvml import *
import atexit

# åœ¨å¯¼å…¥gradioä¹‹å‰æ·»åŠ è¿™äº›ç¯å¢ƒå˜é‡
os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"
os.environ["GRADIO_IS_EVALUATION"] = "False"
#sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
#sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)
task_status_dict = {}  # ç”¨äºå­˜å‚¨ä»»åŠ¡çŠ¶æ€
task_creation_time = {}  # ç”¨äºå­˜å‚¨ä»»åŠ¡çš„å›ºå®šåˆ›å»ºæ—¶é—´
monitor_flag = Event()
def get_resource_usage():
    # CPUåˆ©ç”¨ç‡
    cpu_percent = psutil.cpu_percent(interval=1)
    
    # GPUåˆ©ç”¨ç‡
    gpu_percent = "N/A"
    nvmlInit()
    handle = nvmlDeviceGetHandleByIndex(0)
    util = nvmlDeviceGetUtilizationRates(handle)
    gpu_percent = f"{util.gpu}%"
    
    return f"{cpu_percent}%", gpu_percent

def start_monitoring():
    monitor_flag.set()
    while monitor_flag.is_set():
        cpu, gpu = get_resource_usage()
        yield cpu, gpu
        time.sleep(1)

def stop_monitoring():
    monitor_flag.clear()
    return "å·²åœæ­¢", "å·²åœæ­¢"
# å…¨å±€é…ç½®


# å…¨å±€é…ç½®
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))

PARENT_DIR = os.path.dirname(os.path.dirname(ROOT_DIR))
API_URL = "http://127.0.0.1:6006/generate"
TEMP_DIR = "temp"
#è·å–resultæ‰€åœ¨ç›®å½•ï¼Œè¿™ä¸ªå–å†³äºconfig.iniæ–‡ä»¶
result_dir=os.path.join(PARENT_DIR,"META","app_backen","code")

os.makedirs(TEMP_DIR, exist_ok=True)

# ------------------------- è¯­éŸ³åˆæˆéƒ¨åˆ† -------------------------
import re
REPLACE_RULES = {}  # ç”¨äºå­˜å‚¨æ›¿æ¢è§„åˆ™
CORRECTION_FILE = "å¿µæ³•çº æ­£.txt"  # å›ºå®šçš„æ›¿æ¢è§„åˆ™æ–‡ä»¶å
# æ–°å¢å‡½æ•°ï¼šåŠ è½½æ›¿æ¢è§„åˆ™
def load_replace_rules():
    """ä»å›ºå®šæ–‡ä»¶åŠ è½½æ›¿æ¢è§„åˆ™"""
    global REPLACE_RULES
    REPLACE_RULES = {}
    
    try:
        file_path = os.path.join(ROOT_DIR, CORRECTION_FILE)
        if not os.path.exists(file_path):
            return f"æœªæ‰¾åˆ°æ›¿æ¢è§„åˆ™æ–‡ä»¶: {CORRECTION_FILE}"
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):  # å¿½ç•¥ç©ºè¡Œå’Œæ³¨é‡Š
                    parts = [p.strip() for p in line.split()]
                    if len(parts) >= 2:
                        REPLACE_RULES[parts[0]] = parts[1]
        
        return f"æˆåŠŸåŠ è½½ {len(REPLACE_RULES)} æ¡æ›¿æ¢è§„åˆ™"
    except Exception as e:
        return f"åŠ è½½æ›¿æ¢è§„åˆ™å¤±è´¥: {str(e)}"
    
# æ–°å¢å‡½æ•°ï¼šåº”ç”¨æ›¿æ¢è§„åˆ™
def apply_replace_rules(text):
    """åº”ç”¨æ›¿æ¢è§„åˆ™åˆ°æ–‡æœ¬"""
    load_replace_rules()
    if not REPLACE_RULES:
        return text
    
    for original, replacement in REPLACE_RULES.items():
        text = re.sub(re.escape(original), replacement, text)
    
    return text

def load_preview_audio(speaker_name):
    if not speaker_name:
        return gr.Audio(visible=False), gr.Group(visible=False)
    # åœ¨voicesç›®å½•æŸ¥æ‰¾åŒåçš„MP3æ–‡ä»¶
    audio_path = os.path.join(ROOT_DIR, "voices", f"{speaker_name}.wav")
    if os.path.exists(audio_path):
        return gr.Audio(value=audio_path, visible=True)
    return gr.Audio(visible=False)

def delete_voice_model(voice_name):
    try:
        voice_dir = os.path.join(ROOT_DIR, "voices")
        pt_file = os.path.join(voice_dir, f"{voice_name}.pt")
        wav_file = os.path.join(voice_dir, f"{voice_name}.wav")
        
        if os.path.exists(pt_file):
            os.remove(pt_file)
        if os.path.exists(wav_file):
            os.remove(wav_file)
            
        return f"éŸ³è‰² {voice_name} åˆ é™¤æˆåŠŸ", refresh_voice_list()
    except Exception as e:
        return f"åˆ é™¤å¤±è´¥: {str(e)}", gr.update()
def refresh_voice_list():
    voice_dir = os.path.join(ROOT_DIR, "voices")
    voice_files = []
    if os.path.exists(voice_dir):
        voice_files = [f.replace(".pt", "") for f in os.listdir(voice_dir) 
                     if f.endswith(".pt")]
    return gr.update(choices=voice_files, value=voice_files[0] if voice_files else None)

def generate_audio(tts_text, speaker,
                   emo_control_method="ä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ",
                   vec1=0.0, vec2=0.0, vec3=0.0, vec4=0.0,
                   vec5=0.0, vec6=0.0, vec7=0.0, vec8=0.0,
                   emo_weight=0.65):
    """è°ƒç”¨ http://127.0.0.1:6006/generate API ç”ŸæˆéŸ³é¢‘"""
    # 1. åŸºç¡€å‚æ•°æ ¡éªŒ
    if not tts_text or tts_text.strip() == "":
        return "âŒ è¯·è¾“å…¥åˆæˆæ–‡æœ¬"
    if not speaker:
        return "âŒ è¯·å…ˆé€‰æ‹©éŸ³è‰²"
    
    # 2. å¤„ç†æ–‡æœ¬ï¼ˆåº”ç”¨æ›¿æ¢è§„åˆ™ï¼‰
    processed_text = apply_replace_rules(tts_text.strip())
    
    # 3. è·å–é€‰ä¸­éŸ³è‰²çš„å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆAPIéœ€è¦çš„ prompt_audio å‚æ•°ï¼‰
    prompt_audio_path = os.path.join(ROOT_DIR, "voices", f"{speaker}.wav")
    if not os.path.exists(prompt_audio_path):
        return f"âŒ éŸ³è‰²ã€Œ{speaker}ã€çš„éŸ³é¢‘æ–‡ä»¶ä¸¢å¤±ï¼Œè¯·é‡æ–°å®šåˆ¶"
    
    # 4. æ„é€ APIè¯·æ±‚å‚æ•°ï¼ˆåŒ¹é…ç›®æ ‡APIçš„ form-data æ ¼å¼ï¼‰
    data = {
        "text": processed_text,
        "max_text_tokens_per_segment": 120,
        "do_sample": "true",
        "top_p": 0.8,
        "temperature": 0.8
        # ç§»é™¤APIä¸æ”¯æŒçš„speedå‚æ•°
    }

    # æƒ…æ„Ÿæ§åˆ¶ç›¸å…³å‚æ•°ï¼ˆä¸APIåŒ¹é…ï¼‰
    if emo_control_method == "ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶":
        data["emo_control_method"] = 1  # APIä¸­1è¡¨ç¤ºå‘é‡æ§åˆ¶
        # ä¼ é€’8ç»´æƒ…æ„Ÿå‘é‡ï¼ˆä¸APIå‚æ•°ååŒ¹é…ï¼‰
        data["vec1"] = vec1
        data["vec2"] = vec2
        data["vec3"] = vec3
        data["vec4"] = vec4
        data["vec5"] = vec5
        data["vec6"] = vec6
        data["vec7"] = vec7
        data["vec8"] = vec8
    else:
        # é»˜è®¤ï¼šä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ
        data["emo_control_method"] = 0
    print(emo_control_method,data)
    try:
        # 5. ä½¿ç”¨withè¯­å¥å®‰å…¨å¤„ç†æ–‡ä»¶æµ
        with open(prompt_audio_path, "rb") as f:
            files = {
                "prompt_audio": (
                    os.path.basename(prompt_audio_path),
                    f,
                    "audio/wav"
                )
            }
            
            # 6. å‘é€APIè¯·æ±‚
            response = requests.post(
                "http://127.0.0.1:6006/generate",
                data=data,
                files=files,
                timeout=30000
            )
        
        # 7. å¤„ç†APIå“åº”
        if response.status_code != 200:
            raise Exception(f"APIè¯·æ±‚å¤±è´¥ï¼š{response.status_code}\n{response.text}")
        
        api_result = response.json()
        if api_result.get("status") != "success":
            raise Exception(f"APIè¿”å›å¤±è´¥ï¼š{api_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
        print(api_result)
        # 8. ä¸‹è½½ç”Ÿæˆçš„éŸ³é¢‘
        audio_relative_path = api_result.get("audio_path")
        
        if not audio_relative_path:
            raise Exception("APIæœªè¿”å›éŸ³é¢‘è·¯å¾„")

        # å¤„ç†è·¯å¾„æ ¼å¼
        audio_relative_path = audio_relative_path.replace("\\", "/")
        print(audio_relative_path)
        if not audio_relative_path.startswith('/'):
            audio_relative_path = f'/{audio_relative_path}'
        audio_url = f"http://127.0.0.1:6006{audio_relative_path}"

        # ä¸‹è½½éŸ³é¢‘å¹¶æ£€æŸ¥çŠ¶æ€
        audio_res = requests.get(audio_url, timeout=3000)
        if audio_res.status_code != 200:
            raise Exception(f"éŸ³é¢‘ä¸‹è½½å¤±è´¥ï¼š{audio_res.status_code}")
        
        # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        temp_audio_path = os.path.join(TEMP_DIR, f"gen_{uuid.uuid4().hex[:8]}.wav")
        with open(temp_audio_path, "wb") as f:
            f.write(audio_res.content)
        
        return temp_audio_path
    
    except Exception as e:
        return f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"
 
def customize_voice(prompt_wav, speaker_name):  # ç§»é™¤ prompt_text å‚æ•°
    """ç®€åŒ–ç‰ˆéŸ³è‰²å®šåˆ¶ï¼šä»…å°†ä¸Šä¼ éŸ³é¢‘ä¿å­˜åˆ°voicesç›®å½•"""
    # 1. å‚æ•°æ ¡éªŒ
    if not speaker_name or speaker_name.strip() == "":
        return "âŒ éŸ³è‰²åç§°ä¸èƒ½ä¸ºç©ºï¼Œè¯·è¾“å…¥åç§°"
    if not prompt_wav or not os.path.exists(prompt_wav):
        return "âŒ è¯·å…ˆä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼ˆæ”¯æŒWAV/MP3æ ¼å¼ï¼‰"
    
    # 2. å®šä¹‰ä¿å­˜è·¯å¾„ï¼ˆvoicesç›®å½•ï¼‰
    voices_dir = os.path.join(ROOT_DIR, "voices")
    os.makedirs(voices_dir, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
    target_wav_path = os.path.join(voices_dir, f"{speaker_name.strip()}.wav")
    
    try:
        # 3. éŸ³é¢‘æ ¼å¼ç»Ÿä¸€ï¼ˆè½¬ä¸ºWAVï¼Œé¿å…åç»­ç”ŸæˆæŠ¥é”™ï¼‰
        if prompt_wav.lower().endswith(".wav"):
            # è‹¥å·²æ˜¯WAVï¼Œç›´æ¥å¤åˆ¶
            shutil.copyfile(prompt_wav, target_wav_path)
        else:
            # éWAVæ ¼å¼ï¼ˆå¦‚MP3ï¼‰ï¼Œç”¨ffmpegè½¬ç ä¸ºWAV
            (
                ffmpeg.input(prompt_wav)
                .output(target_wav_path, ac=1, ar=16000)  # å•å£°é“16ké‡‡æ ·ç‡ï¼ˆTTSé€šç”¨æ ¼å¼ï¼‰
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
        
        # 4. ç”Ÿæˆç©ºPTæ–‡ä»¶ï¼ˆå…¼å®¹åŸæœ‰ä»£ç é€»è¾‘ï¼Œé¿å…åç»­åŠ è½½éŸ³è‰²æŠ¥é”™ï¼‰
        target_pt_path = os.path.join(voices_dir, f"{speaker_name.strip()}.pt")
        with open(target_pt_path, "w", encoding="utf-8") as f:
            f.write("voice_placeholder")  # å ä½å†…å®¹
        
        return f"âœ… éŸ³è‰²ã€Œ{speaker_name.strip()}ã€ä¿å­˜æˆåŠŸï¼\nä½ç½®ï¼š{voices_dir}"
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}ï¼ˆè¯·ç¡®ä¿å·²å®‰è£…ffmpegï¼‰"

# ------------------------- æ•°å­—äººéƒ¨åˆ† -------------------------
task_queue = Queue()
def delete_video_model(folder_name):
    try:
        if folder_name == "æ— " or not folder_name:
            return "è¯·é€‰æ‹©æœ‰æ•ˆçš„è§†é¢‘æ¨¡å‹", gr.update()
            
        video_dir = os.path.join(ROOT_DIR, "result", folder_name)
        video_file = os.path.join(video_dir, f"{folder_name}.mp4")
        
        if os.path.exists(video_file):
            os.remove(video_file)
            return f"è§†é¢‘æ¨¡å‹ {folder_name}.mp4 åˆ é™¤æˆåŠŸ", gr.update(choices=get_result_folders())
        return f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ {folder_name}.mp4", gr.update()
    except Exception as e:
        return f"åˆ é™¤å¤±è´¥: {str(e)}", gr.update()
#è·å–ä¸Šä¼ å®šåˆ¶è¿‡çš„æ¨¡ç‰¹åˆ—è¡¨
def get_result_folders():
    result_dir = os.path.join(ROOT_DIR, "result")
    if not os.path.exists(result_dir):
        return ["None"]
    
    valid_folders = []
    for folder in os.listdir(result_dir):
        folder_path = os.path.join(result_dir, folder)
        if os.path.isdir(folder_path):
            # æ£€æŸ¥æ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨ä¸æ–‡ä»¶å¤¹åŒåçš„è§†é¢‘æ–‡ä»¶
            video_file = os.path.join(folder_path, f"{folder}.mp4")
            if os.path.exists(video_file):
                valid_folders.append(folder)
    
    return ["None"] + valid_folders

#è·å–ä¸Šä¼ è§†é¢‘çš„ä¿¡æ¯ï¼Œåˆ†è¾¨ç‡ï¼Œå¸§é€Ÿç‡ï¼ŒéŸ³é¢‘é‡‡æ ·ç‡ç­‰
def get_video_metadata(video_path):
    """å¢å¼ºç‰ˆå…ƒæ•°æ®è·å–ï¼ˆåŒ…å«éŸ³é¢‘å£°é“ä¿¡æ¯ï¼‰"""
    try:
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        probe = ffmpeg.probe(video_path)
        video_stream = next((s for s in probe['streams'] if s['codec_type'] == 'video'), None)
        audio_stream = next((s for s in probe['streams'] if s['codec_type'] == 'audio'), None)

        if not video_stream:
            raise ValueError("æœªæ£€æµ‹åˆ°è§†é¢‘æµ")
            
        # è·å–éŸ³é¢‘å£°é“ä¿¡æ¯
        audio_channels = None
        if audio_stream:
            audio_channels = int(audio_stream.get('channels', 2))
            channel_layout = audio_stream.get('channel_layout', 'stereo' if audio_channels > 1 else 'mono')

        return {
            "width": int(video_stream.get('width', 0)),
            "height": int(video_stream.get('height', 0)),
            "bitrate": int(video_stream.get('bit_rate', 0)) // 1000 if video_stream.get('bit_rate') else None,
            "framerate": eval(video_stream['avg_frame_rate']) if 'avg_frame_rate' in video_stream else None,
            "audio_sample_rate": int(audio_stream.get('sample_rate', 0)) if audio_stream else None,
            "audio_channels": audio_channels,  # æ–°å¢å£°é“æ•°
            "channel_layout": channel_layout,  # æ–°å¢å£°é“å¸ƒå±€
            "codec": video_stream.get('codec_name'),
        }
        
    except Exception as e:
        print(f"è·å–å…ƒæ•°æ®å¤±è´¥: {str(e)}")
        return None
#å¤„ç†
def reprocess_video(input_path, reference_path):

    if input_path is None:
        return None
    metadata = get_video_metadata(reference_path)
    if not metadata:
        return input_path

    output_path = os.path.splitext(input_path)[0] + "_adjusted.mp4"
    
    try:
        # éŸ³é¢‘å‚æ•°è®¾ç½®
        audio_args = {
            'c:a': 'aac',
            'ar': metadata.get("audio_sample_rate", 44100),
            'ac': metadata.get("audio_channels", 2),  # å…³é”®ä¿®æ”¹ï¼šè®¾ç½®å£°é“æ•°
            'channel_layout': metadata.get("channel_layout", 'stereo')  # è®¾ç½®å£°é“å¸ƒå±€
        }

        # è§†é¢‘å‚æ•°è®¾ç½®ï¼ˆä¿æŒä¸å˜ï¼‰
        video_args = {
            'c:v': 'libx264',
            'vf': f'scale={metadata["width"]}:{metadata["height"]}',
            'r': metadata.get("framerate", 30),
            'x264-params': 'nal-hrd=cbr:force-cfr=1',
            'preset': 'medium'
        }

        # æ¯”ç‰¹ç‡æ§åˆ¶
        if metadata.get("bitrate"):
            target_bitrate = metadata["bitrate"]
            video_args.update({
                'b:v': f'{target_bitrate}k',
                'maxrate': f'{target_bitrate}k',
                'minrate': f'{target_bitrate}k',
                'bufsize': f'{target_bitrate}k'
            })
        
        # æ‰§è¡Œè½¬ç 
        (
            ffmpeg.input(input_path)
            .output(output_path, **video_args, **audio_args)
            .overwrite_output()
            .run()
        )
        
        print(f"sucess: {output_path}")
        return output_path
        
    except ffmpeg.Error as e:
        print("FFmpeg wrong:", e.stderr.decode())
    except Exception as e:
        print("fail:", str(e))
    
    return input_path

#æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹ 
def open_output_folder():
    try:
        output_dir = os.path.abspath("result")
        print(output_dir) 
        # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        # æ›´å¯é çš„Windowsæ‰“å¼€æ–¹å¼
        if platform.system() == "Windows":
            # æ–¹æ³•1ï¼šä½¿ç”¨explorer.exeï¼ˆæœ€å¯é ï¼‰
            subprocess.Popen(f'explorer "{output_dir}"', shell=True)
            
            # # æ–¹æ³•2ï¼šå¤‡ç”¨æ–¹æ¡ˆï¼ˆå¦‚æœæ–¹æ³•1å¤±è´¥ï¼‰
            # try:
            #     os.startfile(output_dir)
            # except:
            #     subprocess.run(['start', output_dir], shell=True)
                
            return f"æˆåŠŸæ‰“å¼€æ–‡ä»¶å¤¹ï¼š{output_dir}"
    except Exception as e:
        return f"æ‰“å¼€å¤±è´¥ï¼š{str(e)}"

    
#åŠ è½½é€‰ä¸­çš„è§†é¢‘
def load_selected_video(folder_name):
    if not folder_name:
        return None
    video_filename = f"{folder_name}.mp4"
    video_path = os.path.join(ROOT_DIR,"result", folder_name, video_filename)
    if os.path.exists(video_path):
        return os.path.abspath(video_path)
    return None

#è°ƒç”¨æ¥å£åˆæˆè§†é¢‘
import re  # ç¡®ä¿å¯¼å…¥reæ¨¡å—

def synthesize_video(video_path, audio_path):
    task_code = str(uuid.uuid4())
    print(f"éŸ³é¢‘è·¯å¾„: {audio_path}, è§†é¢‘è·¯å¾„: {video_path}")
    
    payload = {
        "audio_url": audio_path,
        "video_url": video_path,
        "code": task_code,
        "chaofen": 0,
        "watermark_switch": 0,
        "pn": 1
    }
    response = requests.post("http://127.0.0.1:8383/easy/submit", json=payload)
   
    if response.status_code == 200:
        print(f"ä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ä»£ç : {task_code}")
        
        while True:
            progress_response = requests.get(f"http://127.0.0.1:8383/easy/query?code={task_code}")
            progress_data = progress_response.json()
            print(f"ä»»åŠ¡è¿›åº¦: {progress_data}")
            
            status = progress_data.get("data", {}).get("status")
            if status == 2:
                result_path = progress_data.get("data", {}).get("result")
                if result_path:
                    # 1. å¤„ç†è¿”å›çš„è·¯å¾„å­—ç¬¦ä¸²
                    result_path = result_path.replace("\\", "/")  # å°†åæ–œæ è½¬ä¸ºæ­£æ–œæ 
                    result_path = re.sub(r'//+', '/', result_path)  # åˆå¹¶è¿ç»­æ–œæ 
                    
                    # 2. å¤„ç†ç›¸å¯¹è·¯å¾„å‰ç¼€ "./"
                    if result_path.startswith("./"):
                        result_path = result_path[2:]  # ç§»é™¤ "./" å‰ç¼€
                    
                    # 3. æ‹¼æ¥æ­£ç¡®çš„URL
                    if result_path.startswith('/'):
                        video_url = f"http://127.0.0.1:8383{result_path}"
                    else:
                        video_url = f"http://127.0.0.1:8383/{result_path}"
                    
                    print(f"æ­£ç¡®çš„è§†é¢‘URL: {video_url}")
                    return video_url  # è¿”å›å®Œæ•´URLè€Œéæœ¬åœ°è·¯å¾„
                else:
                    return None
            elif status == 1:
                print(f"ä»»åŠ¡è¿›è¡Œä¸­ï¼Œè¿›åº¦: {progress_data.get('data', {}).get('progress')}%")
            else:
                return None
            time.sleep(5)
    else:
        return None
    
#é¢„å¤„ç†è§†é¢‘å’ŒéŸ³é¢‘ï¼Œå°†ä»»åŠ¡æ·»åŠ åˆ°é˜Ÿåˆ—
def save_files(video, audio_folder, audio=None):
    if video is None:
        return "è¯·ä¸Šä¼ è§†é¢‘æˆ–é€‰æ‹©è§†é¢‘æ–‡ä»¶", [],""
    
    video_name = Path(video).stem
    inputvideo_dir = os.path.join("result", video_name)
    os.makedirs(inputvideo_dir, exist_ok=True)
    
    vidoe_id = str(uuid.uuid4())
    video_filename = os.path.basename(video)
    video_dest = os.path.join(TEMP_DIR, f"{vidoe_id}.mp4")
    video_path = os.path.join(inputvideo_dir, video_filename)
    shutil.copy(video, video_dest)
    shutil.copy(video, video_path)

    if audio is not None:
        audio_id = str(uuid.uuid4())
        audio_dest = os.path.join(TEMP_DIR, f"{audio_id}.mp3")
        shutil.copy(audio, audio_dest)
        task_id = f"{vidoe_id}_{audio_id}"
        
        if lang=="en":
            task_status_dict[task_id] = "waiting"
        if lang=="zh-TW":
            task_status_dict[task_id] = "waiting"
        if lang=="zh-CN":
            task_status_dict[task_id] = "waiting"
        task_queue.put((vidoe_id, audio_id, inputvideo_dir))
    
    if audio_folder is not None and audio_folder.strip() != "":
        for audio_file in os.listdir(audio_folder):
            if audio_file.endswith(".mp3") or audio_file.endswith(".wav"):
                audio_id = str(uuid.uuid4())
                audio_dest = os.path.join(TEMP_DIR, f"{audio_id}.mp3")
                audio_path = os.path.join(audio_folder, audio_file)
                shutil.copy(audio_path, audio_dest)
                task_id = f"{vidoe_id}_{audio_id}"
                print("langï¼š",lang)
                if lang=="en":
                    task_status_dict[task_id] = "waiting"
                if lang=="zh-TW":
                    task_status_dict[task_id] = "waiting"
                if lang=="zh-CN":
                    task_status_dict[task_id] = "waiting"
                
                task_queue.put((vidoe_id, audio_id, inputvideo_dir))

    return "ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—ï¼Œè¯·ç­‰å¾…å¤„ç†"
#æŒ‰ç…§é˜Ÿåˆ—æ’é˜Ÿç”Ÿæˆ

def process_queue():
    while True:
        if not task_queue.empty():
            vidoe_id, audio_id, inputvideo_dir = task_queue.get()
            task_id = f"{vidoe_id}_{audio_id}"
            # è®¾ç½®ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
            for lang_code in ["en", "zh-TW", "zh-CN"]:
                if lang == lang_code:
                    task_status_dict[task_id] = "processing"
            
            # è®°å½•ä»»åŠ¡åˆ›å»ºæ—¶é—´
            if task_id not in task_creation_time:
                task_creation_time[task_id] = datetime.now()
            
            tempvideo_path = os.path.abspath(os.path.join(TEMP_DIR, f"{vidoe_id}.mp4"))
            tempaudio_path = os.path.abspath(os.path.join(TEMP_DIR, f"{audio_id}.mp3"))
            
            try:
                # è·å–è§†é¢‘URL
                video_url = synthesize_video(tempvideo_path, tempaudio_path)
                print("è§†é¢‘URLï¼š", video_url)
                
                if not video_url:
                    task_status_dict[task_id] = "failed: æœªè·å–åˆ°è§†é¢‘URL"
                    task_queue.task_done()
                    continue
                
                # ä»URLä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
                temp_result_path = os.path.join(TEMP_DIR, f"temp_{uuid.uuid4().hex}.mp4")
                response = requests.get(video_url, stream=True, timeout=60)
                response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
                
                with open(temp_result_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                
                # å¤„ç†ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶
                result_path = os.path.join(inputvideo_dir, f"{audio_id}_output.mp4")
                print("ç»“æœæ–‡ä»¶å¤¹ï¼š", result_path)
                
                # å¤åˆ¶ç»“æœæ–‡ä»¶
                shutil.copy(temp_result_path, result_path)
                
                # åå¤„ç†è§†é¢‘
                result_path_final = reprocess_video(result_path, tempvideo_path)
                
                # æ·»åŠ åˆ°ç”Ÿæˆçš„è§†é¢‘åˆ—è¡¨
                if not hasattr(app, "generated_videos"):
                    app.generated_videos = []
                app.generated_videos.append(result_path_final)
                print(app.generated_videos)
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                if not hasattr(app, "task_status"):
                    app.task_status = ""
                status_msg = f"task doneï¼š{result_path_final}\n"
                for lang_code in ["en", "zh-TW", "zh-CN"]:
                    if lang == lang_code:
                        app.task_status += status_msg
                
                print(app.task_status)
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                for file_path in [tempvideo_path, tempaudio_path, temp_result_path, result_path]:
                    if os.path.exists(file_path):
                        try:
                            os.remove(file_path)
                        except Exception as e:
                            print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {file_path} å¤±è´¥: {str(e)}")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
                for lang_code in ["en", "zh-TW", "zh-CN"]:
                    if lang == lang_code:
                        task_status_dict[task_id] = "Done"
                
            except requests.exceptions.RequestException as e:
                task_status_dict[task_id] = f"failed: è§†é¢‘ä¸‹è½½å¤±è´¥ - {str(e)}"
                print(f"è§†é¢‘ä¸‹è½½å‡ºé”™: {str(e)}")
            except Exception as e:
                task_status_dict[task_id] = f"failed: {str(e)}"
                print(f"ä»»åŠ¡å¤„ç†å‡ºé”™: {str(e)}")
            finally:
                task_queue.task_done()
        else:
            time.sleep(1)

def cleanup_temp_files(path):
    """æ¸…ç†æ‰€æœ‰ä¸´æ—¶éŸ³è§†é¢‘æ–‡ä»¶"""
    TEMP_DIR1=path
    print(TEMP_DIR1)
    try:
        if os.path.exists(TEMP_DIR1):
            for filename in os.listdir(TEMP_DIR1):
                file_path = os.path.join(TEMP_DIR1, filename)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                    elif os.path.isdir(file_path):
                        shutil.rmtree(file_path)
                except Exception as e:
                    print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        print("ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
    except Exception as e:
        print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def get_task_status():
    status_html = """
    <style>
        .task-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 10px;
        }
        .task-table th, .task-table td {
            border: 1px solid #444;
            padding: 8px 12px;
            text-align: left;
        }
        .task-table th {
            background-color: #333;
        }
        .task-waiting {
            color: #FFA500;
        }
        .task-processing {
            color: #1E90FF;
        }
        .task-completed {
            color: #32CD32;
        }
        .task-failed {
            color: #FF4500;
        }
    </style>
    <table class="task-table">
        <tr>
            <th>ä»»åŠ¡ID</th>
            <th>çŠ¶æ€</th>
            <th>åˆ›å»ºæ—¶é—´</th>
        </tr>
    """
    
    for task_id, status in task_status_dict.items():
        status_class = f"task-{status.lower()}"
        short_id = task_id[:8] + "..." + task_id[-4:]  # ç¼©çŸ­æ˜¾ç¤ºçš„ID
        
        # è·å–å›ºå®šçš„åˆ›å»ºæ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰è®°å½•åˆ™ä½¿ç”¨å½“å‰æ—¶é—´ï¼ˆå…¼å®¹æ—§ä»»åŠ¡ï¼‰
        create_time = task_creation_time.get(task_id, datetime.now())
        
        status_html += f"""
        <tr>
            <td>{short_id}</td>
            <td class="{status_class}">{status}</td>
            <td>{create_time.strftime('%Y-%m-%d %H:%M:%S')}</td>
        </tr>
        """
    
    status_html += "</table>"
    return status_html
# å¯åŠ¨ä»»åŠ¡å¤„ç†çº¿ç¨‹
threading.Thread(target=process_queue, daemon=True).start()
# åœ¨ with gr.Blocks() ä¹‹å‰æ·»åŠ è‡ªå®šä¹‰ CSS
def get_task_status_en():
    status_html = """
    <style>
        .task-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 10px;
        }
        .task-table th, .task-table td {
            border: 1px solid #444;
            padding: 8px 12px;
            text-align: left;
        }
        .task-table th {
            background-color: #333;
        }
        .task-waiting {
            color: #FFA500;
        }
        .task-processing {
            color: #1E90FF;
        }
        .task-completed {
            color: #32CD32;
        }
        .task-failed {
            color: #FF4500;
        }
    </style>
    <table class="task-table">
        <tr>
            <th>Task ID</th>
            <th>Status</th>
            <th>Created At</th>
        </tr>
    """
    
    for task_id, status in task_status_dict.items():
        status_class = f"task-{status.lower()}"
        short_id = task_id[:8] + "..." + task_id[-4:]  # Shorten displayed ID
        
        # Get creation time, use current time if not recorded (for backward compatibility)
        create_time = task_creation_time.get(task_id, datetime.now())
        
        # Translate status if needed (optional)
        status_text = {
            "waiting": "Waiting",
            "processing": "Processing",
            "completed": "Completed",
            "failed": "Failed"
        }.get(status.lower(), status)
        
        status_html += f"""
        <tr>
            <td>{short_id}</td>
            <td class="{status_class}">{status_text}</td>
            <td>{create_time.strftime('%Y-%m-%d %H:%M:%S')}</td>
        </tr>
        """
    
    status_html += "</table>"
    return status_html

custom_css="""
/* éšè— Gradio é¡µè„š */
footer {
    display: none !important;
}
:root {
    /* åŸºç¡€é¢œè‰² */
    --body-background-fill: #252525 !important;  /* æœ€åº•å±‚èƒŒæ™¯ */
    --block-background-fill: #252525 !important;  /* å¡ç‰‡èƒŒæ™¯ */
    --input-background-fill: #252525 !important;  /* è¾“å…¥æ¡†èƒŒæ™¯ */
    
    /* æ–‡å­—é¢œè‰² */
    --body-text-color: #888888 !important;
    --block-title-text-color: #888888 !important;
    --label-text-color: #888888 !important;
    
    /* è¾¹æ¡†å’Œäº¤äº’å…ƒç´  */
    --border-color-primary: #3a3a3a !important;
    --button-primary-background-fill: #4a8cff !important;
    --slider-color: #4a8cff !important;
    
    /* ç‰¹æ®Šç»„ä»¶ */
    --checkbox-label-text-color: #c0c0c0 !important;
    --label-text-color: #c0c0c0 !important;  /* ä¸»æ ‡ç­¾é¢œè‰² */
    --block-label-text-color: #252525 !important;  /* åŒºå—æ ‡ç­¾é¢œè‰² */
    --primary-btn-color: #6a75ff;
    --primary-btn-hover: #5d68f0;
}
/* ===== å¼ºåˆ¶è¦†ç›–æ‰€æœ‰æ ‡ç­¾ç±»å‹ ===== */
.gr-form > .gr-form-group > label,          /* å¸¸è§„è¾“å…¥æ ‡ç­¾ */
.gr-input > label,                          /* è¾“å…¥æ¡†æ ‡ç­¾ */
.gr-slider > label,                         /* æ»‘å—æ ‡ç­¾ */
.gr-radio > label,                          /* å•é€‰æ ‡ç­¾ */
.gr-checkbox > label,                       /* å¤šé€‰æ ‡ç­¾ */
.gr-file > label,                           /* æ–‡ä»¶ä¸Šä¼ æ ‡ç­¾ */
.gr-audio > label,                          /* éŸ³é¢‘æ ‡ç­¾ */
.gr-video > label,                          /* è§†é¢‘æ ‡ç­¾ */
.gr-image > label,                          /* å›¾ç‰‡æ ‡ç­¾ */
.gr-plot > label,                           /* å›¾è¡¨æ ‡ç­¾ */
.gr-dataframe > label,                      /* æ•°æ®æ¡†æ ‡ç­¾ */
.gr-json > label,                           /* JSONæ ‡ç­¾ */
.gr-html > label,                           /* HTMLæ ‡ç­¾ */
.gr-markdown > .label {                     /* MarkdownåŒºåŸŸæ ‡ç­¾ */
    color: #1a1a1a !important;
    font-weight: 500;
}
button.primary {
    background: var(--primary-btn-color) !important;
    border-color: var(--primary-btn-color) !important;
}

button.primary:hover {
    background: var(--primary-btn-hover) !important;
}

button.primary:active {
    filter: brightness(90%);
}

/* è¡¨æ ¼æ ‡ç­¾ */
.gr-table th {
    color: #c0c0c0 !important;
}
/* éŸ³é¢‘ç»„ä»¶å®šåˆ¶ */
.audio-container {
    background: linear-gradient(180deg, #1a1a1a 0%, #333333 100%) !important;
    border-radius: 8px !important;
}

/* è§†é¢‘ç»„ä»¶å®šåˆ¶ */
.video-container {
    background: linear-gradient(180deg, #1a1a1a 0%, #333333 100%) !important;
}

/* æ ‡ç­¾ç»„ */
.gr-group {
    background: #252525 !important;
    border: 1px solid #3a3a3a !important;
}
.gr-audio label,
.gr-video label {
    display: none !important;
}
/* è¦†ç›–æ‰€æœ‰æ–‡æœ¬ */
* {
    color: #e0e0e0 !important;
}
.custom-btn {
    background: #6a75ff !important;
    border-color: #6a75ff !important;
    color: white !important;
}

.custom-btn:hover {
    background: #5d68f0 !important;
    border-color: #5d68f0!important;
}

.custom-btn:active {
    background: #2f35c7 !important;
}
/* ä¸‹æ‹‰èœå•å±•å¼€åçš„å®¹å™¨èƒŒæ™¯ */


.custom-dropdown li {
    transition: background-color 0.3s ease;
}
.custom-textbox{
    background: linear-gradient(180deg, #1a1a1a 0%, #333333 100%) !important;
    box-shadow: 0 2px 8px rgba(0,0,0,0.3);
}

.gradio-dropdown .gradio-dropdown-options .gradio-dropdown-option {
    color: #000 !important; /* è®¾ç½®ä¸ºé»‘è‰² */
}
.tabs {
    padding: 0px !important; /* è®¾ç½®é€‰é¡¹å¡çš„å†…è¾¹è· */
    font-size: 16px !important; /* è®¾ç½®é€‰é¡¹å¡çš„å­—ä½“å¤§å° */
}
.tab_buttun{
    font-size: 20px !important; 
}
/* ä¸‹æ‹‰è¾“å…¥æ¡† */
[role="combobox"], 
[role="listbox"] {
  background: #252525 !important;
  border-color: var(--border-color-primary) !important;
}

/* ä¸‹æ‹‰é€‰é¡¹é¢æ¿ */
[role="listbox"] > div {
  background: #2525FF !important;
  border: 1px solid var(--border-color-primary) !important;
  box-shadow: var(--shadow-drop-lg) !important;
}

/* å•ä¸ªé€‰é¡¹ */
[role="option"] {
  color: var(--body-text-color) !important;
  padding: 8px 12px !important;
}

/* æ‚¬åœé€‰é¡¹ */
[role="option"]:hover {
  background: #252525 !important;
  color: white !important;
}

/* é€‰ä¸­é€‰é¡¹ */
[role="option"][aria-selected="true"] {
  background: #252525 !important;
}
.tab-container[role="tablist"] {
    gap: 30px !important; /* è°ƒæ•´æ ‡ç­¾é—´è· */
  
}
.tab-container[role="tablist"] button.svelte-1tcem6n {
    font-family: "PingFang SC", "HarmonyOS Sans SC", "Microsoft YaHei", sans-serif !important;
    font-size: 16px !important;
    font-weight: 600 !important; /* ä¸­ç­‰åŠ ç²— */
    letter-spacing: 0.5px !important; /* è½»å¾®å­—è· */
    text-transform: uppercase !important; /* è‹±æ–‡å¤§å†™ */
    padding: 12px 24px !important;
    color:#888888 !important;
    transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1) !important;
}
/* æ‚¬åœçŠ¶æ€çš„tabæ ‡ç­¾ */
.tab-container[role="tablist"] button.svelte-1tcem6n:hover {
    background: #2d2d2d !important;

}
.tab-container[role="tablist"] button.svelte-1tcem6n.selected {
    background: transparent !important;
    color: inherit !important;
}
.tab-container[role="tablist"] button.svelte-1tcem6n.selected::after {
    content: "";
    position: absolute;
    bottom: -15px; /* å¯¹é½å®¹å™¨åº•éƒ¨å†…è¾¹è· */
    left: 0;
    right: 0;
    height: 8px;
    background: #6a75ff !important; /* ç°è‰²æ¨ªæ¡ */
    border-radius: 2px;
}
/* éšè—å€é€ŸæŒ‰é’® */
.custom-audio-preview button.playback.icon.svelte-ije4bl {
    display: none !important;
}
.scroll[part="scroll"] {
  overflow-x: hidden !important; /* ç¦ç”¨æ°´å¹³æ»šåŠ¨ */

}
.gradio-container {
    background: #252525 !important;
}
.styler.svelte-1nguped {
    background-color: #252525 !important;
    /* å…¶ä»–æ ·å¼... */
}
.form {
    gap: 10px !important;
}

.gr-group {
    gap: 10px !important;
}

.column.gap {
    gap: 12px !important;
}

.row.unequal-height {
    gap: 16px !important;
}

.gradio-container * {
    border-radius: 5px !important;
}
/* ä¿®æ”¹æ‰€æœ‰blockå…ƒç´ çš„è¾¹æ¡†ä¸ºéšè— */
.block.svelte-5y6bt2 {
    border-style: none !important;
}

/* ä¿®æ”¹ç‰¹å®šç»„ä»¶çš„è¾¹æ¡†ä¸ºéšè— */
.gr-group.svelte-1nguped .styler {
    --block-border-width: 0px !important;
}

/* ä¿®æ”¹è¡¨å•å…ƒç´ çš„è¾¹æ¡†ä¸ºéšè— */
.form.svelte-633qhp {
    border-style: none !important;
}

/* ä¿®æ”¹æ ‡ç­¾å®¹å™¨çš„è¾¹æ¡†ä¸ºéšè— */
.label.svelte-p5q82i {
    border-style: none !important;
}
.gradio-container.gradio-container-5-4-0 .contain .gr-group  {
    border: none !important;
    box-shadow: none !important;
    background: transparent !important;
}

.tabitem.svelte-tcemt9 {
    padding-top: 10px !important;
}
#component-42.block.custom-audio.svelte-5y6bt2 {
    background-color: #303030 !important;
}
#component-54.block.svelte-5y6bt2.padded {
    background-color: #303030 !important;
}
#component-49.block.custom-dropdown.svelte-5y6bt2 {
    background-color: linear-gradient(180deg, #1a1a1a 0%, #333333 100%) !important;

}
#component-68.block.custom-gallery.svelte-5y6bt2 {
    background-color: #303030 !important;
}
#component-134.block.svelte-5y6bt2.padded {
    background-color: #303030 !important;
}
#component-122.block.custom-audio.svelte-5y6bt2 {
    background-color: #303030 !important;
}
#component-148.block.custom-gallery.svelte-5y6bt2 {
    background-color: #303030 !important;
}
#component-214.block.svelte-5y6bt2.padded {
    background-color: #303030 !important;
}
#component-202.block.custom-audio.svelte-5y6bt2 {
    background-color: #303030 !important;
}
#component-228.block.custom-gallery.svelte-5y6bt2 {
    background-color: #303030 !important;
}
/* å®¹å™¨æ ·å¼ */
#component-169 .wrap.svelte-12ioyct {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  text-align: center;
  position: relative;
  font-size: 0;
}

/* å›¾æ ‡æ ·å¼ï¼ˆæ­£ç¡®å±‚çº§ï¼‰ */
#component-169 .wrap.svelte-12ioyct > .icon-wrap.svelte-12ioyct {
  font-size: initial;
  margin-bottom: 8px;
}

/* ä¸‰è¡Œæ–‡æœ¬ï¼ˆä½¿ç”¨::afterï¼‰ */
#component-169 .wrap.svelte-12ioyct::after {
  content: "Drop audio here\A - or -\A Click to upload";
  white-space: pre;
  font-size: 20px;
  line-height: 1.5;
  text-align: center;
  display: block;
  margin-top: 4px;
}

/* éšè—åŸå§‹æ–‡æœ¬ */
#component-169 .wrap.svelte-12ioyct > :not(.icon-wrap),
#component-211 .or.svelte-12ioyct {
  display: none;
}

/* å®¹å™¨æ ·å¼ */
#component-211 .wrap.svelte-12ioyct {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  text-align: center;
  position: relative;
  font-size: 0;
}

/* å›¾æ ‡æ ·å¼ï¼ˆæ­£ç¡®å±‚çº§ï¼‰ */
#component-211 .wrap.svelte-12ioyct > .icon-wrap.svelte-12ioyct {
  font-size: initial;
  margin-bottom: 8px;
}

/* ä¸‰è¡Œæ–‡æœ¬ï¼ˆä½¿ç”¨::afterï¼‰ */
#component-211 .wrap.svelte-12ioyct::after {
  content: "Drop video here\A - or -\A Click to upload";
  white-space: pre;
  font-size: 20px;
  line-height: 1.5;
  text-align: center;
  display: block;
  margin-top: 4px;
}

/* éšè—åŸå§‹æ–‡æœ¬ */
#component-211 .wrap.svelte-12ioyct > :not(.icon-wrap),
#component-211 .or.svelte-12ioyct {
  display: none;
}

/* å®¹å™¨æ ·å¼ */
#component-217 .wrap.svelte-12ioyct {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  text-align: center;
  position: relative;
  font-size: 0;
}

/* å›¾æ ‡æ ·å¼ï¼ˆæ­£ç¡®å±‚çº§ï¼‰ */
#component-217 .wrap.svelte-12ioyct > .icon-wrap.svelte-12ioyct {
  font-size: initial;
  margin-bottom: 8px;
}

/* ä¸‰è¡Œæ–‡æœ¬ï¼ˆä½¿ç”¨::afterï¼‰ */
#component-217 .wrap.svelte-12ioyct::after {
  content: "Drop audio here\A - or -\A Click to upload";
  white-space: pre;
  font-size: 20px;
  line-height: 1.5;
  text-align: center;
  display: block;
  margin-top: 4px;
}

/* éšè—åŸå§‹æ–‡æœ¬ */
#component-217 .wrap.svelte-12ioyct > :not(.icon-wrap),
#component-217 .or.svelte-12ioyct {
  display: none;
}
/* æƒ…æ„Ÿæ§åˆ¶åŒºåŸŸæ•´ä½“æ ·å¼ */
.emotion-control-section {
    margin: 15px 0;
}

/* Radioç»„ä»¶æ ·å¼ */
#component-emo-control-method {
    background: #252525;
    border: 1px solid #3a3a3a;
    border-radius: 6px;
    padding: 12px;
    margin: 8px 0;
}

#component-emo-control-method label {
    color: #e0e0e0 !important;
    font-size: 15px !important;
    margin-bottom: 8px !important;
    display: block !important;
}

#component-emo-control-method .gr-radio-group {
    display: flex !important;
    gap: 15px !important;
    flex-wrap: wrap !important;
}

#component-emo-control-method input[type="radio"] {
    margin-right: 6px !important;
    accent-color: #6a75ff !important;
}

#component-emo-control-method .gr-radio-label {
    color: #d0d0d0 !important;
    font-size: 14px !important;
    cursor: pointer !important;
}

/* æƒ…æ„Ÿå‘é‡ç»„å®¹å™¨æ ·å¼ */
.gr-group:has(> .markdown-body h3) {
    background: #252525 !important;
    border: 1px solid #3a3a3a !important;
    border-radius: 6px !important;
    padding: 15px !important;
    margin: 10px 0 !important;
}

/* æƒ…æ„Ÿå‘é‡æ ‡é¢˜æ ·å¼ */
.markdown-body h3:contains("æƒ…æ„Ÿå‘é‡è°ƒèŠ‚") {
    font-size: 16px !important;
    font-weight: 600 !important;
    color: #e0e0e0 !important;
    margin: 0 0 12px 0 !important;
    padding-bottom: 8px !important;
    border-bottom: 1px solid #3a3a3a !important;
}

/* æ»‘å—é€šç”¨æ ·å¼ */
.gr-slider {
    margin: 10px 0 !important;
}

.gr-slider label {
    color: #e0e0e0 !important;
    font-size: 14px !important;
    margin-bottom: 5px !important;
    display: block !important;
}

.gr-slider input[type="range"] {
    width: 100% !important;
    background: #3a3a3a !important;
    height: 6px !important;
    border-radius: 3px !important;
}

.gr-slider input[type="range"]::-webkit-slider-thumb {
    background: #6a75ff !important;
    border: none !important;
    width: 16px !important;
    height: 16px !important;
    border-radius: 50% !important;
    cursor: pointer !important;
}

/* æƒ…æ„Ÿæƒé‡æ»‘å—å®¹å™¨ */
.gr-row:has(> .gr-slider label:contains("æƒ…æ„Ÿæƒé‡")) {
    background: #252525 !important;
    border: 1px solid #3a3a3a !important;
    border-radius: 6px !important;
    padding: 12px 15px !important;
    margin: 5px 0 !important;
}
/* æƒ…æ„Ÿæ§åˆ¶é€‰é¡¹èƒŒæ™¯é€æ˜ */


/* æƒ…æ„Ÿå‘é‡è°ƒèŠ‚åŒºåŸŸç¼©å° */
.emotion-vector-section {
    margin: 10px 0 !important;
    padding: 8px !important;
}

/* æƒ…æ„Ÿå‘é‡æ ‡é¢˜ç¼©å° */
.emotion-vector-title {
    font-size: 14px !important;
    margin: 0 0 8px 0 !important;
    padding-bottom: 5px !important;
}
label.selected.svelte-1bx8sav.svelte-1bx8sav.svelte-1bx8sav {
    /* background: var(--checkbox-label-background-fill-selected); */
    color: var(--checkbox-label-text-color-selected);
    border-color: var(--checkbox-label-border-color-selected);
}
label.svelte-1bx8sav.svelte-1bx8sav.svelte-1bx8sav {
    display: flex
;
    align-items: center;
    transition: var(--button-transition);
    cursor: pointer;
    box-shadow: var(--checkbox-label-shadow);
    border: var(--checkbox-label-border-width) solid var(--checkbox-label-border-color);
    border-radius: var(--checkbox-border-radius);
    background: transparent;
    padding: var(--checkbox-label-padding);
    color: var(--checkbox-label-text-color);
    font-weight: var(--checkbox-label-text-weight);
    font-size: var(--checkbox-label-text-size);
    line-height: var(--line-md);
}
"""


    


# ------------------------- ä¸»ç•Œé¢ -------------------------
def create_chinese_simplified_block():
    with gr.Blocks(title="CosyVoice æ•°å­—äººç³»ç»Ÿ") as demo:
        with gr.Tabs(elem_classes="tab_buttun") as tabs:
            # ç¬¬ä¸€é¡µï¼šéŸ³è‰²å®šåˆ¶
            with gr.TabItem("ğŸ™ï¸ éŸ³è‰²å®šåˆ¶", id="tab1",elem_classes="tabs"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ä¸Šä¼ å‚è€ƒéŸ³é¢‘",elem_classes="Markdown")
                        gr.Markdown("éŸ³é¢‘æ—¶é•¿35sä»¥å†…",elem_classes="Markdown")
                        prompt_wav = gr.Audio(
                            show_label=False,
                            type="filepath",
                            interactive=True,
                            elem_classes="custom-audio"  # æ·»åŠ  CSS ç±»
                        )
                        gr.Markdown("### è®¾ç½®éŸ³è‰²å‚æ•°")
                        with gr.Group(elem_classes="custom-group"):
                            speaker_name = gr.Textbox(
                                label="éŸ³è‰²åç§°", 
                                placeholder="ä¸ºæ‚¨çš„éŸ³è‰²èµ·ä¸ªåå­—",
                                info="å»ºè®®ä½¿ç”¨è‹±æ–‡å‘½å",
                                elem_classes="custom-textbox"  # æ·»åŠ  CSS ç±»
                            )
                        customize_btn = gr.Button(
                            "âœ¨ å¼€å§‹å®šåˆ¶éŸ³è‰²", 
                            variant="primary",
                            elem_classes="custom-btn"  # æ·»åŠ  CSS ç±»
                        )

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### å®šåˆ¶ç»“æœ")
                        customize_output = gr.Textbox(
                            label="çŠ¶æ€ä¿¡æ¯",
                            interactive=False,
                            placeholder="ç­‰å¾…éŸ³è‰²å®šåˆ¶...",
                            elem_classes="custom-textbox"  # æ·»åŠ  CSS ç±»
                        )

            # ç¬¬äºŒé¡µï¼šè¯­éŸ³åˆæˆ
            with gr.TabItem("ğŸ”Š è¯­éŸ³åˆæˆ", id="tab2",elem_classes="tabs"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### é€‰æ‹©éŸ³è‰²ä¸æ–‡æœ¬")
                        with gr.Row():
                            voice_dir = os.path.join(ROOT_DIR, "voices")
                            voice_files = []
                            if os.path.exists(voice_dir):
                                voice_files = [f.replace(".pt", "") for f in os.listdir(voice_dir) if f.endswith(".pt")]
                            with gr.Column(scale=1):
                                with gr.Row():
                                    speaker = gr.Dropdown(
                                        label="é€‰æ‹©å®šåˆ¶éŸ³è‰²", 
                                        choices=voice_files,
                                        value=voice_files[0] if voice_files else None,
                                        interactive=True,
                                        elem_classes="custom-dropdown"  # æ·»åŠ  CSS ç±»
                                    )
                                    preview_audio = gr.Audio(
                                        show_label=False,
                                        interactive=False,
                                        visible=False,
                                        elem_classes="custom-audio-preview" 
                                    )
                                    with gr.Column():
                                        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", size="sm", elem_classes="custom-btn")  # æ·»åŠ  CSS ç±»
                                        delete_voice_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤éŸ³è‰²", size="sm", variant="stop", elem_classes="custom-btn") 

                        tts_text = gr.Textbox(
                            label="è¾“å…¥åˆæˆæ–‡æœ¬", 
                            placeholder="è¯·è¾“å…¥è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡å­—å†…å®¹...",
                            lines=14,
                            elem_classes="custom-textbox"  # æ·»åŠ  CSS ç±»
                        )
                        # -------------------------- æ–°å¢ï¼šæƒ…æ„Ÿå‘é‡æ§åˆ¶UI --------------------------
                        # 1. æƒ…æ„Ÿæ§åˆ¶æ–¹å¼é€‰æ‹©ï¼ˆåªä¿ç•™ã€Œä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒã€ã€Œä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶ã€ä¸¤ä¸ªé€‰é¡¹ï¼‰
                        emo_control_method = gr.Radio(
                            label="æƒ…æ„Ÿæ§åˆ¶æ–¹å¼",
                            choices=["ä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ", "ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶"],
                            value="ä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ",  # é»˜è®¤ä¸å¯ç”¨æƒ…æ„Ÿå‘é‡
                            interactive=True
                        )

                        # 2. æƒ…æ„Ÿå‘é‡æ»‘å—ç»„ï¼ˆé»˜è®¤éšè—ï¼Œä»…å½“é€‰æ‹©ã€Œä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶ã€æ—¶æ˜¾ç¤ºï¼‰
                        # æ›¿æ¢åŸæœ‰çš„æƒ…æ„Ÿå‘é‡ç›¸å…³ä»£ç 
                        with gr.Group(visible=False) as emotion_vector_group:
                            gr.Markdown("### æƒ…æ„Ÿå‘é‡è°ƒèŠ‚ï¼ˆ8ç»´åº¦ï¼‰", elem_classes="emotion-vector-title")
                            with gr.Row(elem_classes="emotion-vector-section"):
                                with gr.Column(scale=1):
                                    vec1 = gr.Slider(label="å–œ", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec2 = gr.Slider(label="æ€’", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec3 = gr.Slider(label="å“€", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec4 = gr.Slider(label="æƒ§", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                with gr.Column(scale=1):
                                    vec5 = gr.Slider(label="åŒæ¶", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec6 = gr.Slider(label="ä½è½", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec7 = gr.Slider(label="æƒŠå–œ", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec8 = gr.Slider(label="å¹³é™", minimum=0.0, maximum=1.0, value=0.0, step=0.05)

                        # 3. æƒ…æ„Ÿæƒé‡ï¼ˆé»˜è®¤éšè—ï¼Œæ§åˆ¶æƒ…æ„Ÿå‘é‡å½±å“ç¨‹åº¦ï¼‰
                        with gr.Row(visible=False) as emo_weight_group:
                            emo_weight = gr.Slider(label="æƒ…æ„Ÿæƒé‡", minimum=0.0, maximum=1.0, value=0.65, step=0.01)
                        # --------------------------------------------------------------------------
                        with gr.Row():
                            generate_btn = gr.Button("ğŸµ ç”ŸæˆéŸ³é¢‘", variant="primary")  # æ·»åŠ  CSS ç±»
                            go_to_digital_human_btn = gr.Button("â¡ï¸ å‰å¾€æ•°å­—äººåˆæˆ", variant="secondary", elem_classes="custom-btn")  # æ·»åŠ  CSS ç±»

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### ç”Ÿæˆç»“æœ")
                        output_audio = gr.Audio(
                            show_label=False,
                            interactive=False,
                            waveform_options={
                                "waveform_progress_color": "#4a8cff"
                            },
                            elem_classes="custom-audio",  # æ·»åŠ  CSS ç±»
                            show_download_button=True
                        )
                        gr.Examples(
                            examples=["ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨è¯­éŸ³å…‹éš†ç³»ç»Ÿ", "ä»Šå¤©å¤©æ°”çœŸå¥½"],
                            inputs=[tts_text],
                            label="è¯•è¯•ç¤ºä¾‹æ–‡æœ¬",
                        
                        )

            # ç¬¬ä¸‰é¡µï¼šæ•°å­—äººåˆæˆ
            with gr.TabItem("ğŸ¬ æ•°å­—äººåˆæˆ", id="tab3",elem_classes="tabs", visible=False):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### é€‰æ‹©ç´ æ")
                        with gr.Group(elem_classes="custom-group"):
                            model_dir = os.path.join(ROOT_DIR, "result")
                            #print(model_dir)
                            folders=get_result_folders()
                            
                            dropdown = gr.Dropdown(
                                choices= folders, 
                                label="é€‰æ‹©å·²æœ‰è§†é¢‘æ¨¡æ¿",
                                info="æˆ–ä¸Šä¼ æ–°è§†é¢‘",
                                elem_classes="custom-dropdown"  # æ·»åŠ  CSS ç±»
                            )
                            delete_video_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤æ¨¡æ¿", variant="stop", elem_classes="custom-btn")  # æ–°å¢åˆ é™¤æŒ‰é’®
                            video_input = gr.Video(
                                show_label=False,
                                sources=["upload"],
                                format="mp4",
                                elem_classes="custom-video"  # æ·»åŠ  CSS ç±»
                            )
                        
                        gr.Markdown("### æ·»åŠ éŸ³é¢‘")
                        with gr.Accordion("æ‰¹é‡ç”Ÿæˆé€‰é¡¹", open=False):
                            audio_folder_input = gr.Textbox(
                                label="éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„",
                                placeholder="è¾“å…¥åŒ…å«å¤šä¸ªéŸ³é¢‘æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„",
                                elem_classes="custom-textbox"  # æ·»åŠ  CSS ç±»
                            )
                        single_audio_input = gr.Audio(
                            show_label=False,
                            type="filepath",
                            elem_classes="custom-audio"  # æ·»åŠ  CSS ç±»
                        )
                        save_button = gr.Button("ğŸš€ ç”Ÿæˆæ•°å­—äººè§†é¢‘", variant="primary", elem_classes="custom-btn")  # æ·»åŠ  CSS ç±»

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### ç”Ÿæˆç»“æœ")
                        with gr.Tab("çŠ¶æ€ä¿¡æ¯"):
                            result_text = gr.Textbox(
                                visible=False,
                                label="å¤„ç†è¿›åº¦",
                                interactive=False,
                                elem_classes="custom-textbox"  # æ·»åŠ  CSS ç±»
                            )
                            task_status_html = gr.HTML(
                            value=get_task_status(),
                            label="å½“å‰ä»»åŠ¡çŠ¶æ€"
                            )
                            
                            task_status_text = gr.Textbox(
                                label="è¯¦ç»†æ—¥å¿—", 
                                interactive=False,
                                lines=4,
                                elem_classes="custom-textbox"  # æ·»åŠ  CSS ç±»
                            )
                        with gr.Tab("è§†é¢‘é¢„è§ˆ"):
                            video_gallery = gr.Gallery(
                                show_label=False,
                                columns=2,
                                height="auto",
                                object_fit="contain",
                                elem_classes="custom-gallery"  # æ·»åŠ  CSS ç±»
                            )
                        open_folder_btn = gr.Button("ğŸ“ æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹", elem_classes="custom-btn")  # æ·»åŠ  CSS ç±»
                        gr.Markdown("### å®æ—¶èµ„æºåˆ©ç”¨ç‡")
                        with gr.Row():
                            cpu_usage = gr.Textbox(label="CPUåˆ©ç”¨ç‡", interactive=False)
                            gpu_usage = gr.Textbox(label="GPUåˆ©ç”¨ç‡", interactive=False)
                        with gr.Row():
                            monitor_btn = gr.Button("ğŸ“ˆ å¼€å§‹å®æ—¶ç›‘æ§", variant="secondary", elem_classes="custom-btn")
                            stop_monitor_btn = gr.Button("â¹ï¸ åœæ­¢ç›‘æ§", variant="stop", elem_classes="custom-btn")

        # äº‹ä»¶ç»‘å®šï¼ˆåŸæœ‰é€»è¾‘ä¿æŒä¸å˜ï¼‰
        
        refresh_btn.click(refresh_voice_list, outputs=speaker)
        customize_btn.click(customize_voice, inputs=[prompt_wav,speaker_name], outputs=customize_output)
        # -------------------------- æ–°å¢ï¼šæƒ…æ„Ÿæ§åˆ¶æ–¹å¼åˆ‡æ¢é€»è¾‘ --------------------------
        def on_emo_method_change(emo_method):
            # åˆ¤æ–­æ˜¯å¦é€‰æ‹©ã€Œä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶ã€
            if emo_method == "ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶":
                return (
                    gr.update(visible=True),  # æ˜¾ç¤ºæƒ…æ„Ÿå‘é‡æ»‘å—ç»„
                    gr.update(visible=True)   # æ˜¾ç¤ºæƒ…æ„Ÿæƒé‡æ»‘å—
                )
            else:
                return (
                    gr.update(visible=False),  # éšè—æƒ…æ„Ÿå‘é‡æ»‘å—ç»„
                    gr.update(visible=False)   # éšè—æƒ…æ„Ÿæƒé‡æ»‘å—
                )

        # ç»‘å®šRadioé€‰æ‹©å˜åŒ–äº‹ä»¶ï¼šå½“ã€Œæƒ…æ„Ÿæ§åˆ¶æ–¹å¼ã€æ”¹å˜æ—¶ï¼Œæ›´æ–°UIæ˜¾ç¤º
        emo_control_method.change(
            fn=on_emo_method_change,
            inputs=[emo_control_method],
            outputs=[emotion_vector_group, emo_weight_group]
        )
        # --------------------------------------------------------------------------
       
        generate_btn.click(
            generate_audio, 
            inputs=[
                tts_text, speaker,  # åŸæœ‰å‚æ•°
                # æ–°å¢æƒ…æ„Ÿç›¸å…³å‚æ•°ï¼ˆéœ€ä¸generate_audioå‡½æ•°å‚æ•°é¡ºåºä¸€è‡´ï¼‰
                emo_control_method,
                vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8,
                emo_weight
            ],
            outputs=[output_audio]
        )
        go_to_digital_human_btn.click(
            fn=lambda audio: (gr.Tabs(selected="tab3"), audio),
            inputs=output_audio,
            outputs=[tabs, single_audio_input]
        )
        dropdown.change(load_selected_video, inputs=dropdown, outputs=[video_input])
        open_folder_btn.click(
            fn=open_output_folder,
            outputs=gr.Textbox(visible=False)  # æ— å®é™…è¾“å‡ºï¼Œä»…è§¦å‘åŠ¨ä½œ
        )
        save_button.click(
            save_files,
            inputs=[video_input, audio_folder_input, single_audio_input],
            outputs=[result_text]
        )
        monitor_btn.click(
            fn=start_monitoring,
            outputs=[cpu_usage, gpu_usage]
        )
        delete_voice_btn.click(
            fn=delete_voice_model,
            inputs=[speaker],
            outputs=[result_text, speaker]
        )

        delete_video_btn.click(
            fn=delete_video_model,
            inputs=[dropdown],
            outputs=[result_text, dropdown]
        )
        speaker.change(
            load_preview_audio,
            inputs=speaker,
            outputs=[preview_audio]
        )
        stop_monitor_btn.click(
            fn=stop_monitoring,
            outputs=[cpu_usage, gpu_usage]
        )
        def auto_refresh_tasks():
            while True:
                time.sleep(1)
                yield get_task_status()
        demo.load(auto_refresh_tasks, outputs=task_status_html)
    
        # è‡ªåŠ¨åˆ·æ–°
        def update_interface():
            if hasattr(app, "generated_videos"):
                return app.generated_videos, app.task_status if hasattr(app, "task_status") else ""
            return [], ""

        def auto_refresh():
            while True:
                time.sleep(1)
                if hasattr(app, "generated_videos"):
                    yield update_interface()

        save_button.click(auto_refresh, inputs=None, outputs=[video_gallery, task_status_text])#ç‚¹å‡»ç”Ÿæˆåå¼€å§‹æ›´æ–°video_gallery, task_status_text
        return demo
    
def create_chinese_traditional_block():
    with gr.Blocks(title="CosyVoice æ•¸å­—äººç³»çµ±", css=custom_css) as demo:
        with gr.Tabs(elem_classes="tab_buttun") as tabs:
            # ç¬¬ä¸€é ï¼šéŸ³è‰²å®šåˆ¶
            with gr.TabItem("ğŸ™ï¸ éŸ³è‰²å®šåˆ¶", id="tab1", elem_classes="tabs"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ä¸Šå‚³åƒè€ƒéŸ³é »", elem_classes="Markdown")
                        gr.Markdown("éŸ³é »æ™‚é•·35sä»¥å…§", elem_classes="Markdown")
                        prompt_wav = gr.Audio(
                            show_label=False,
                            type="filepath",
                            interactive=True,
                            elem_classes="custom-audio"
                        )
                        gr.Markdown("### è¨­ç½®éŸ³è‰²åƒæ•¸")
                        with gr.Group(elem_classes="custom-group"):
                            prompt_text = gr.Textbox(
                                label="åƒè€ƒéŸ³é »æ–‡æœ¬ï¼ˆè‡ªå‹•è­˜åˆ¥ï¼‰",
                                placeholder="éŸ³é »è­˜åˆ¥çµæœå°‡è‡ªå‹•é¡¯ç¤ºåœ¨é€™è£¡",
                                lines=2,
                                elem_classes="custom-textbox"
                            )
                            speaker_name = gr.Textbox(
                                label="éŸ³è‰²åç¨±", 
                                placeholder="ç‚ºæ‚¨çš„éŸ³è‰²èµ·å€‹åå­—",
                                info="å»ºè­°ä½¿ç”¨è‹±æ–‡å‘½å",
                                elem_classes="custom-textbox"
                            )
                        customize_btn = gr.Button(
                            "âœ¨ é–‹å§‹å®šåˆ¶éŸ³è‰²", 
                            variant="primary",
                            elem_classes="custom-btn"
                        )

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### å®šåˆ¶çµæœ")
                        customize_output = gr.Textbox(
                            label="ç‹€æ…‹ä¿¡æ¯",
                            interactive=False,
                            placeholder="ç­‰å¾…éŸ³è‰²å®šåˆ¶...",
                            elem_classes="custom-textbox"
                        )

            # ç¬¬äºŒé ï¼šèªéŸ³åˆæˆ
            with gr.TabItem("ğŸ”Š èªéŸ³åˆæˆ", id="tab2", elem_classes="tabs"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### é¸æ“‡éŸ³è‰²èˆ‡æ–‡æœ¬")
                        with gr.Row():
                            voice_dir = os.path.join(ROOT_DIR, "voices")
                            voice_files = []
                            if os.path.exists(voice_dir):
                                voice_files = [f.replace(".pt", "") for f in os.listdir(voice_dir) if f.endswith(".pt")]
                            with gr.Column(scale=1):
                                with gr.Row():
                                    speaker = gr.Dropdown(
                                        label="é¸æ“‡å®šåˆ¶éŸ³è‰²", 
                                        choices=voice_files,
                                        value=voice_files[0] if voice_files else None,
                                        interactive=True,
                                        elem_classes="custom-dropdown"
                                    )
                                    preview_audio = gr.Audio(
                                        show_label=False,
                                        interactive=False,
                                        visible=False,
                                        elem_classes="custom-audio-preview" 
                                    )
                                    with gr.Column():
                                        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", size="sm", elem_classes="custom-btn")
                                        delete_voice_btn = gr.Button("ğŸ—‘ï¸ åˆªé™¤éŸ³è‰²", size="sm", variant="stop", elem_classes="custom-btn") 

                        tts_text = gr.Textbox(
                            label="è¼¸å…¥åˆæˆæ–‡æœ¬", 
                            placeholder="è«‹è¼¸å…¥è¦è½‰æ›ç‚ºèªéŸ³çš„æ–‡å­—å…§å®¹...",
                            lines=14,
                            elem_classes="custom-textbox"
                        )
                        # æƒ…æ„Ÿæ§åˆ¶æ–¹å¼é€‰æ‹©
                        emo_control_method = gr.Radio(
                            label="æƒ…æ„Ÿæ§åˆ¶æ–¹å¼",
                            choices=["èˆ‡éŸ³è‰²åƒè€ƒéŸ³é »ç›¸åŒ", "ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶"],
                            value="èˆ‡éŸ³è‰²åƒè€ƒéŸ³é »ç›¸åŒ",
                            interactive=True
                        )

                        # æƒ…æ„Ÿå‘é‡æ»‘å—ç»„
                        with gr.Group(visible=False) as emotion_vector_group:
                            gr.Markdown("### æƒ…æ„Ÿå‘é‡èª¿ç¯€ï¼ˆ8ç¶­åº¦ï¼‰", elem_classes="emotion-vector-title")
                            with gr.Row(elem_classes="emotion-vector-section"):
                                with gr.Column(scale=1):
                                    vec1 = gr.Slider(label="å–œ", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec2 = gr.Slider(label="æ€’", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec3 = gr.Slider(label="å“€", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec4 = gr.Slider(label="æ‡¼", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                with gr.Column(scale=1):
                                    vec5 = gr.Slider(label="å­æƒ¡", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec6 = gr.Slider(label="ä½è½", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec7 = gr.Slider(label="é©šå–œ", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec8 = gr.Slider(label="å¹³éœ", minimum=0.0, maximum=1.0, value=0.0, step=0.05)

                        # æƒ…æ„Ÿæƒé‡
                        with gr.Row(visible=False) as emo_weight_group:
                            emo_weight = gr.Slider(label="æƒ…æ„Ÿæ¬Šé‡", minimum=0.0, maximum=1.0, value=0.65, step=0.01)


                        with gr.Row():
                            generate_btn = gr.Button("ğŸµ ç”ŸæˆéŸ³é »", variant="primary")
                            go_to_digital_human_btn = gr.Button("â¡ï¸ å‰å¾€æ•¸å­—äººåˆæˆ", variant="secondary", elem_classes="custom-btn")

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### ç”Ÿæˆçµæœ")
                        output_audio = gr.Audio(
                            show_label=False,
                            interactive=False,
                            waveform_options={
                                "waveform_progress_color": "#4a8cff"
                            },
                            elem_classes="custom-audio"
                        )
                        gr.Examples(
                            examples=["ä½ å¥½ï¼Œæ­¡è¿ä½¿ç”¨èªéŸ³å…‹éš†ç³»çµ±", "ä»Šå¤©å¤©æ°£çœŸå¥½"],
                            inputs=[tts_text],
                            label="è©¦è©¦ç¤ºä¾‹æ–‡æœ¬",
                        )

            # ç¬¬ä¸‰é ï¼šæ•¸å­—äººåˆæˆ
            with gr.TabItem("ğŸ¬ æ•¸å­—äººåˆæˆ", id="tab3", elem_classes="tabs", visible=False):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### é¸æ“‡ç´ æ")
                        with gr.Group(elem_classes="custom-group"):
                            model_dir = os.path.join(ROOT_DIR, "result")
                            folders = get_result_folders()
                            
                            dropdown = gr.Dropdown(
                                choices=folders, 
                                label="é¸æ“‡å·²æœ‰è¦–é »æ¨¡æ¿",
                                info="æˆ–ä¸Šå‚³æ–°è¦–é »",
                                elem_classes="custom-dropdown"
                            )
                            delete_video_btn = gr.Button("ğŸ—‘ï¸ åˆªé™¤æ¨¡æ¿", variant="stop", elem_classes="custom-btn")
                            video_input = gr.Video(
                                show_label=False,
                                sources=["upload"],
                                format="mp4",
                                elem_classes="custom-video"
                            )
                        
                        gr.Markdown("### æ·»åŠ éŸ³é »")
                        with gr.Accordion("æ‰¹é‡ç”Ÿæˆé¸é …", open=False):
                            audio_folder_input = gr.Textbox(
                                label="éŸ³é »æ–‡ä»¶å¤¾è·¯å¾‘",
                                placeholder="è¼¸å…¥åŒ…å«å¤šå€‹éŸ³é »æ–‡ä»¶çš„æ–‡ä»¶å¤¾è·¯å¾‘",
                                elem_classes="custom-textbox"
                            )
                        single_audio_input = gr.Audio(
                            show_label=False,
                            type="filepath",
                            elem_classes="custom-audio"
                        )
                        save_button = gr.Button("ğŸš€ ç”Ÿæˆæ•¸å­—äººè¦–é »", variant="primary", elem_classes="custom-btn")

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### ç”Ÿæˆçµæœ")
                        with gr.Tab("ç‹€æ…‹ä¿¡æ¯"):
                            result_text = gr.Textbox(
                                visible=False,
                                label="è™•ç†é€²åº¦",
                                interactive=False,
                                elem_classes="custom-textbox"
                            )
                            task_status_html = gr.HTML(
                                value=get_task_status(),
                                label="ç•¶å‰ä»»å‹™ç‹€æ…‹"
                            )
                            
                            task_status_text = gr.Textbox(
                                label="è©³ç´°æ—¥èªŒ", 
                                interactive=False,
                                lines=4,
                                elem_classes="custom-textbox"
                            )
                        with gr.Tab("è¦–é »é è¦½"):
                            video_gallery = gr.Gallery(
                                show_label=False,
                                columns=2,
                                height="auto",
                                object_fit="contain",
                                elem_classes="custom-gallery"
                            )
                        open_folder_btn = gr.Button("ğŸ“ æ‰“é–‹è¼¸å‡ºæ–‡ä»¶å¤¾", elem_classes="custom-btn")
                        gr.Markdown("### å¯¦æ™‚è³‡æºåˆ©ç”¨ç‡")
                        with gr.Row():
                            cpu_usage = gr.Textbox(label="CPUåˆ©ç”¨ç‡", interactive=False)
                            gpu_usage = gr.Textbox(label="GPUåˆ©ç”¨ç‡", interactive=False)
                        with gr.Row():
                            monitor_btn = gr.Button("ğŸ“ˆ é–‹å§‹å¯¦æ™‚ç›£æ§", variant="secondary", elem_classes="custom-btn")
                            stop_monitor_btn = gr.Button("â¹ï¸ åœæ­¢ç›£æ§", variant="stop", elem_classes="custom-btn")
        # äº‹ä»¶ç»‘å®šï¼ˆåŸæœ‰é€»è¾‘ä¿æŒä¸å˜ï¼‰
        # æ·»åŠ æƒ…æ„Ÿæ§åˆ¶åˆ‡æ¢é€»è¾‘
        def on_emo_method_change(emo_method):
            if emo_method == "ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶":
                return (gr.update(visible=True), gr.update(visible=True))
            else:
                return (gr.update(visible=False), gr.update(visible=False))

        emo_control_method.change(
            fn=on_emo_method_change,
            inputs=[emo_control_method],
            outputs=[emotion_vector_group, emo_weight_group]
        )   
        generate_btn.click(
            generate_audio, 
            inputs=[
                tts_text, speaker,
                emo_control_method,
                vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8,
                emo_weight
            ],
            outputs=output_audio
        )     
        refresh_btn.click(refresh_voice_list, outputs=speaker)
        customize_btn.click(customize_voice, inputs=[prompt_wav,  speaker_name], outputs=customize_output)
        go_to_digital_human_btn.click(
            fn=lambda audio: (gr.Tabs(selected="tab3"), audio),
            inputs=output_audio,
            outputs=[tabs, single_audio_input]
        )
        dropdown.change(load_selected_video, inputs=dropdown, outputs=[video_input])
        open_folder_btn.click(
            fn=open_output_folder,
            outputs=gr.Textbox(visible=False)  # æ— å®é™…è¾“å‡ºï¼Œä»…è§¦å‘åŠ¨ä½œ
        )
        save_button.click(
            save_files,
            inputs=[video_input, audio_folder_input, single_audio_input],
            outputs=[result_text]
        )
        monitor_btn.click(
        fn=start_monitoring,
        outputs=[cpu_usage, gpu_usage]
        )
        delete_voice_btn.click(
            fn=delete_voice_model,
            inputs=[speaker],
            outputs=[result_text, speaker]
        )

        delete_video_btn.click(
            fn=delete_video_model,
            inputs=[dropdown],
            outputs=[result_text, dropdown]
        )
        speaker.change(
        load_preview_audio,
        inputs=speaker,
        outputs=[preview_audio]
        )
        stop_monitor_btn.click(
            fn=stop_monitoring,
            outputs=[cpu_usage, gpu_usage]
        )
        def auto_refresh_tasks():
            while True:
                time.sleep(1)
                yield get_task_status()
        demo.load(auto_refresh_tasks, outputs=task_status_html)
    
        # è‡ªåŠ¨åˆ·æ–°
        def update_interface():
            if hasattr(app, "generated_videos"):
                return app.generated_videos, app.task_status if hasattr(app, "task_status") else ""
            return [], ""

        def auto_refresh():
            while True:
                time.sleep(1)
                if hasattr(app, "generated_videos"):
                
                    yield update_interface()

        save_button.click(auto_refresh, inputs=None, outputs=[video_gallery, task_status_text])#ç‚¹å‡»ç”Ÿæˆåå¼€å§‹æ›´æ–°video_gallery, task_status_text
        
        return demo

def create_english_block():
    with gr.Blocks(title="CosyVoice Digital Human System", css=custom_css) as demo:
        with gr.Tabs(elem_classes="tab_buttun") as tabs:
            # Tab 1: Voice Customization
            with gr.TabItem("ğŸ™ï¸ Voice Custom", id="tab1", elem_classes="tabs"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### Upload Reference Audio", elem_classes="Markdown")
                        gr.Markdown("Audio duration within 35s", elem_classes="Markdown")
                        prompt_wav = gr.Audio(
                            show_label=False,
                            type="filepath",
                            interactive=True,
                            elem_classes="custom-audio"
                        )
                        gr.Markdown("### Voice Parameters")
                        with gr.Group(elem_classes="custom-group"):
                            prompt_text = gr.Textbox(
                                label="Reference Audio Text (Auto Recognized)",
                                placeholder="Audio recognition results will appear here",
                                lines=2,
                                elem_classes="custom-textbox"
                            )
                            speaker_name = gr.Textbox(
                                label="Voice Name", 
                                placeholder="Name your voice",
                                info="Recommended to use English names",
                                elem_classes="custom-textbox"
                            )
                        customize_btn = gr.Button(
                            "âœ¨ Start Customization", 
                            variant="primary",
                            elem_classes="custom-btn"
                        )

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### Customization Result")
                        customize_output = gr.Textbox(
                            label="Status Information",
                            interactive=False,
                            placeholder="Waiting for voice customization...",
                            elem_classes="custom-textbox"
                        )

            # Tab 2: Speech Synthesis
            with gr.TabItem("ğŸ”Š TTS", id="tab2", elem_classes="tabs"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### Select Voice & Text")
                        with gr.Row():
                            voice_dir = os.path.join(ROOT_DIR, "voices")
                            voice_files = []
                            if os.path.exists(voice_dir):
                                voice_files = [f.replace(".pt", "") for f in os.listdir(voice_dir) if f.endswith(".pt")]
                            with gr.Column(scale=1):
                                with gr.Row():
                                    speaker = gr.Dropdown(
                                        label="Select Custom Voice", 
                                        choices=voice_files,
                                        value=voice_files[0] if voice_files else None,
                                        interactive=True,
                                        elem_classes="custom-dropdown"
                                    )
                                    preview_audio = gr.Audio(
                                        show_label=False,
                                        interactive=False,
                                        visible=False,
                                        elem_classes="custom-audio-preview" 
                                    )
                                    with gr.Column():
                                        refresh_btn = gr.Button("ğŸ”„ Refresh List", size="sm", elem_classes="custom-btn")
                                        delete_voice_btn = gr.Button("ğŸ—‘ï¸ Delete Voice", size="sm", variant="stop", elem_classes="custom-btn") 

                        tts_text = gr.Textbox(
                            label="Input Text", 
                            placeholder="Enter text to convert to speech...",
                            lines=14,
                            elem_classes="custom-textbox"
                        )
                        # æƒ…æ„Ÿæ§åˆ¶æ–¹å¼é€‰æ‹©
                        emo_control_method = gr.Radio(
                            label="Emotion Control Method",
                            choices=["Same as Reference Audio", "Use Emotion Vector Control"],
                            value="Same as Reference Audio",
                            interactive=True
                        )

                        # æƒ…æ„Ÿå‘é‡æ»‘å—ç»„
                        with gr.Group(visible=False) as emotion_vector_group:
                            gr.Markdown("### Emotion Vector Adjustment (8 Dimensions)", elem_classes="emotion-vector-title")
                            with gr.Row(elem_classes="emotion-vector-section"):
                                with gr.Column(scale=1):
                                    vec1 = gr.Slider(label="Joy", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec2 = gr.Slider(label="Anger", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec3 = gr.Slider(label="Sorrow", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec4 = gr.Slider(label="Fear", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                with gr.Column(scale=1):
                                    vec5 = gr.Slider(label="Disgust", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec6 = gr.Slider(label="Depression", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec7 = gr.Slider(label="Surprise", minimum=0.0, maximum=1.0, value=0.0, step=0.05)
                                    vec8 = gr.Slider(label="Calm", minimum=0.0, maximum=1.0, value=0.0, step=0.05)

                        # æƒ…æ„Ÿæƒé‡
                        with gr.Row(visible=False) as emo_weight_group:
                            emo_weight = gr.Slider(label="Emotion Weight", minimum=0.0, maximum=1.0, value=0.65, step=0.01)


                        with gr.Row():
                            generate_btn = gr.Button("ğŸµ Generate Audio", variant="primary")
                            go_to_digital_human_btn = gr.Button("â¡ï¸ Go to Digital Human", variant="secondary", elem_classes="custom-btn")

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### Generation Result")
                        output_audio = gr.Audio(
                            show_label=False,
                            interactive=False,
                            waveform_options={
                                "waveform_progress_color": "#4a8cff"
                            },
                            elem_classes="custom-audio"
                        )
                        gr.Examples(
                            examples=["Hello, welcome to the voice cloning system", "The weather is nice today"],
                            inputs=[tts_text],
                            label="Try Example Texts",
                        )

            # Tab 3: Digital Human
            with gr.TabItem("ğŸ¬ Digital Human", id="tab3", elem_classes="tabs", visible=False):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### Select Materials")
                        with gr.Group(elem_classes="custom-group"):
                            model_dir = os.path.join(ROOT_DIR, "result")
                            folders = get_result_folders()
                            
                            dropdown = gr.Dropdown(
                                choices=folders, 
                                label="Select Existing Video Template",
                                info="Or upload new video",
                                elem_classes="custom-dropdown"
                            )
                            delete_video_btn = gr.Button("ğŸ—‘ï¸ Delete Template", variant="stop", elem_classes="custom-btn")
                            video_input = gr.Video(
                                show_label=False,
                                sources=["upload"],
                                format="mp4",
                                elem_classes="custom-video"
                            )
                        
                        gr.Markdown("### Add Audio")
                        with gr.Accordion("Batch Generation Options", open=False):
                            audio_folder_input = gr.Textbox(
                                label="Audio Folder Path",
                                placeholder="Enter folder path containing multiple audio files",
                                elem_classes="custom-textbox"
                            )
                        single_audio_input = gr.Audio(
                            show_label=False,
                            type="filepath",
                            elem_classes="custom-audio"
                        )
                        save_button = gr.Button("ğŸš€ Generate Digital Human Video", variant="primary", elem_classes="custom-btn")

                    with gr.Column(scale=1, elem_classes="output-section"):
                        gr.Markdown("### Generation Result")
                        with gr.Tab("Status Information"):
                            result_text = gr.Textbox(
                                visible=False,
                                label="Processing Progress",
                                interactive=False,
                                elem_classes="custom-textbox"
                            )
                            task_status_html = gr.HTML(
                                value=get_task_status_en(),
                                label="Current Task Status"
                            )
                            
                            task_status_text = gr.Textbox(
                                label="Detailed Logs", 
                                interactive=False,
                                lines=4,
                                elem_classes="custom-textbox"
                            )
                        with gr.Tab("Video Preview"):
                            video_gallery = gr.Gallery(
                                show_label=False,
                                columns=2,
                                height="auto",
                                object_fit="contain",
                                elem_classes="custom-gallery"
                            )
                        open_folder_btn = gr.Button("ğŸ“ Open Output Folder", elem_classes="custom-btn")
                        gr.Markdown("### Real-time Resource Usage")
                        with gr.Row():
                            cpu_usage = gr.Textbox(label="CPU Usage", interactive=False)
                            gpu_usage = gr.Textbox(label="GPU Usage", interactive=False)
                        with gr.Row():
                            monitor_btn = gr.Button("ğŸ“ˆ Start Monitoring", variant="secondary", elem_classes="custom-btn")
                            stop_monitor_btn = gr.Button("â¹ï¸ Stop Monitoring", variant="stop", elem_classes="custom-btn")
        # äº‹ä»¶ç»‘å®šï¼ˆåŸæœ‰é€»è¾‘ä¿æŒä¸å˜ï¼‰
        # æ·»åŠ æƒ…æ„Ÿæ§åˆ¶åˆ‡æ¢é€»è¾‘
        def on_emo_method_change(emo_method):
            if emo_method == "Use Emotion Vector Control":
                return (gr.update(visible=True), gr.update(visible=True))
            else:
                return (gr.update(visible=False), gr.update(visible=False))

        emo_control_method.change(
            fn=on_emo_method_change,
            inputs=[emo_control_method],
            outputs=[emotion_vector_group, emo_weight_group]
        )  
        generate_btn.click(
            generate_audio, 
            inputs=[
                tts_text, speaker,
                emo_control_method,
                vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8,
                emo_weight
            ],
            outputs=output_audio
        )     
        refresh_btn.click(refresh_voice_list, outputs=speaker)
        customize_btn.click(customize_voice, inputs=[prompt_wav, speaker_name], outputs=customize_output)
        # æ›´æ–°generate_btnçš„clickäº‹ä»¶ï¼Œå¢åŠ instruct_textè¾“å…¥

        go_to_digital_human_btn.click(
            fn=lambda audio: (gr.Tabs(selected="tab3"), audio),
            inputs=output_audio,
            outputs=[tabs, single_audio_input]
        )
        dropdown.change(load_selected_video, inputs=dropdown, outputs=[video_input])
        open_folder_btn.click(
            fn=open_output_folder,
            outputs=gr.Textbox(visible=False)  # æ— å®é™…è¾“å‡ºï¼Œä»…è§¦å‘åŠ¨ä½œ
        )
        save_button.click(
            save_files,
            inputs=[video_input, audio_folder_input, single_audio_input],
            outputs=[result_text]
        )
        monitor_btn.click(
        fn=start_monitoring,
        outputs=[cpu_usage, gpu_usage]
        )
        delete_voice_btn.click(
            fn=delete_voice_model,
            inputs=[speaker],
            outputs=[result_text, speaker]
        )

        delete_video_btn.click(
            fn=delete_video_model,
            inputs=[dropdown],
            outputs=[result_text, dropdown]
        )
        speaker.change(
        load_preview_audio,
        inputs=speaker,
        outputs=[preview_audio]
        )
        stop_monitor_btn.click(
            fn=stop_monitoring,
            outputs=[cpu_usage, gpu_usage]
        )
        def auto_refresh_tasks():
            while True:
                time.sleep(1)
                yield get_task_status_en()
        demo.load(auto_refresh_tasks, outputs=task_status_html)
    
        # è‡ªåŠ¨åˆ·æ–°
        def update_interface():
            if hasattr(app, "generated_videos"):
                return app.generated_videos, app.task_status if hasattr(app, "task_status") else ""
            return [], ""

        def auto_refresh():
            while True:
                time.sleep(1)
                if hasattr(app, "generated_videos"):
                    yield update_interface()

        save_button.click(auto_refresh, inputs=None, outputs=[video_gallery, task_status_text])#ç‚¹å‡»ç”Ÿæˆåå¼€å§‹æ›´æ–°video_gallery, task_status_text
        
        return demo




# è¯­è¨€åå¥½æ–‡ä»¶è·¯å¾„
LANGUAGE_FILE = "language_preference.txt"

def get_saved_language():
    """è¯»å–ä¿å­˜çš„è¯­è¨€åå¥½ï¼Œé»˜è®¤è¿”å› 'zh-CN'"""
    if os.path.exists(LANGUAGE_FILE):
        try:
            with open(LANGUAGE_FILE, "r", encoding="utf-8") as f:
                lang = f.read().strip()
                if lang in ["zh-CN", "zh-TW", "en"]:
                    return lang
        except Exception as e:
            print(f"è¯»å–è¯­è¨€åå¥½æ–‡ä»¶å¤±è´¥: {e}")
    return "zh-CN"  # é»˜è®¤ç®€ä½“ä¸­æ–‡
lang=get_saved_language()
def save_language(lang):
    """ä¿å­˜è¯­è¨€åå¥½åˆ°æ–‡ä»¶"""
    try:
        with open(LANGUAGE_FILE, "w", encoding="utf-8") as f:
            f.write(lang)
    except Exception as e:
        print(f"ä¿å­˜è¯­è¨€åå¥½å¤±è´¥: {e}")

def create_main_app():
    # è·å–ä¸Šæ¬¡ä¿å­˜çš„è¯­è¨€
    initial_lang = get_saved_language()

    with gr.Blocks(title="å¤šè¯­è¨€åº”ç”¨", css=custom_css) as app:
        # åˆ›å»ºè¯­è¨€åŒºå—ï¼ˆåˆå§‹çŠ¶æ€ç”± initial_lang å†³å®šï¼‰
        with gr.Group(visible=initial_lang == "zh-CN", elem_id="cn_block") as cn_block:
            cn_ui = create_chinese_simplified_block()
        
        with gr.Group(visible=initial_lang == "zh-TW", elem_id="tw_block") as tw_block:
            tw_ui = create_chinese_traditional_block()
            
        with gr.Group(visible=initial_lang == "en", elem_id="en_block") as en_block:
            en_ui = create_english_block()

        # éšè—æ–‡æœ¬æ¡†ï¼Œç”¨äºæ¥æ”¶è¯­è¨€åˆ‡æ¢æŒ‡ä»¤ï¼ˆåˆå§‹å€¼ä¸ºä¿å­˜çš„è¯­è¨€ï¼‰
        lang_display = gr.Textbox(
            value=initial_lang,
            visible=False,
            interactive=False,
            elem_id="lang_display"
        )

        # è¯­è¨€åˆ‡æ¢é€»è¾‘ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ + ä¿å­˜åˆ°æ–‡ä»¶ï¼‰
        def switch_language(language):
            print(f"[DEBUG] åˆ‡æ¢è¯­è¨€: {language}")
            lang=language
            save_language(lang)  # æ–°å¢ï¼šä¿å­˜åˆ°æ–‡ä»¶
            return [
                gr.update(visible=lang == "zh-CN"),  # cn_block
                gr.update(visible=lang == "zh-TW"),  # tw_block
                gr.update(visible=lang == "en")      # en_block
            ]

        # ç›‘å¬è¯­è¨€åˆ‡æ¢ï¼ˆåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
        lang_display.input(
            fn=switch_language,
            inputs=lang_display,
            outputs=[cn_block, tw_block, en_block]
        )

        # åˆå§‹åŒ–æ—¶è‡ªåŠ¨åº”ç”¨ä¸Šæ¬¡ä¿å­˜çš„è¯­è¨€ï¼ˆåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
        app.load(
            None,
            None,
            None,
            js="""
            function() {
                console.log("[JS DEBUG] åˆå§‹åŒ–è¯­è¨€ç›‘å¬å™¨...");
                
                // 1. è‡ªåŠ¨è§¦å‘åˆå§‹è¯­è¨€ï¼ˆç”±åç«¯ä¼ é€’çš„ initial_lang å†³å®šï¼‰
                const displayBox = document.getElementById('lang_display');
                if (displayBox) {
                    const textarea = displayBox.querySelector('textarea');
                    if (textarea) {
                        // è§¦å‘è¯­è¨€åˆ‡æ¢
                        const inputEvent = new Event('input', { bubbles: true });
                        textarea.dispatchEvent(inputEvent);
                    }
                }
                
                // 2. ä¿ç•™åŸæœ‰çš„çˆ¶çª—å£æ¶ˆæ¯ç›‘å¬ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
                window.addEventListener('message', (event) => {
                    console.log("[JS DEBUG] æ”¶åˆ°æ¶ˆæ¯:", event.data);
                    
                    if (event.data?.type === 'language-change') {
                        const lang = event.data.language;
                        console.log("[JS DEBUG] å¤„ç†è¯­è¨€åˆ‡æ¢:", lang);
                        
                        const displayBox = document.getElementById('lang_display');
                        if (displayBox) {
                            const textarea = displayBox.querySelector('textarea');
                            if (textarea) {
                                textarea.value = lang;
                                // è§¦å‘ input äº‹ä»¶
                                const inputEvent = new Event('input', { bubbles: true });
                                textarea.dispatchEvent(inputEvent);
                            }
                        }
                    }
                });
                
                return [];
            }
            """
        )
    
    return app

if __name__ == "__main__":

    app = create_main_app()
    app.launch(
        allowed_paths=[ROOT_DIR]
    )

